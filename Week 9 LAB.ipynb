{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### You will need mlens package in addition to the libraries you are familiar with\n",
    "## pip install mlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same data as we used in today's class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEEK 9 LAB: \n",
    "1. LOOP THROUGH MODELS AS DONE IN THIS WEEK'S CLASS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for clf, label in zip([LR, RF, KNC, DTC, ABC, BC, GBC, XGB],\n",
    "#                       ['Logistic Regression',\n",
    "#                        'Random Forest',\n",
    "#                        'KNeighbors',\n",
    "#                        'Decision Tree',\n",
    "#                        'Ada Boost',\n",
    "#                        'Bagging',\n",
    "#                        'Gradient Boosting',\n",
    "#                        'XGBoost']):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>WorkClass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationNum</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Gender</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>NativeCountry</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>257302</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>154374</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>151910</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>201490</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>287927</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  WorkClass  fnlwgt  Education  EducationNum  MaritalStatus  \\\n",
       "32555   27          4  257302          7            12              2   \n",
       "32556   40          4  154374         11             9              2   \n",
       "32557   58          4  151910         11             9              6   \n",
       "32558   22          4  201490         11             9              4   \n",
       "32559   52          5  287927         11             9              2   \n",
       "\n",
       "       Occupation  Relationship  Race  Gender  CapitalGain  CapitalLoss  \\\n",
       "32555          13             5     4       0            0            0   \n",
       "32556           7             0     4       1            0            0   \n",
       "32557           1             4     4       0            0            0   \n",
       "32558           1             3     4       1            0            0   \n",
       "32559           4             5     4       0        15024            0   \n",
       "\n",
       "       HoursPerWeek  NativeCountry  Income  \n",
       "32555            38             39       0  \n",
       "32556            40             39       1  \n",
       "32557            40             39       0  \n",
       "32558            20             39       0  \n",
       "32559            40             39       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "col_names = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "\n",
    "df = pandas.read_csv('~/Documents/Machine_Learning/LAB/Week9/adult.data')\n",
    "df.columns=col_names\n",
    "df['Income'] = df['Income'].apply(lambda x: 0 if x == ' <=50K' else 1)\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == type(object):\n",
    "        le = sklearn.preprocessing.LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Income')\n",
    "y = df['Income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=555, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n",
      "Train CV Accuracy: 0.791 (+/- 0.008) [Logistic Regression]\n",
      "Test Accuracy: 0.8034 \n",
      "Train CV Accuracy: 0.856 (+/- 0.004) [Random Forest]\n",
      "Test Accuracy: 0.8575 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/payal/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/payal/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/payal/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/payal/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/payal/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV Accuracy: 0.772 (+/- 0.002) [KNeighbors]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/payal/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7794 \n",
      "Train CV Accuracy: 0.811 (+/- 0.004) [Decision Tree]\n",
      "Test Accuracy: 0.8150 \n",
      "Train CV Accuracy: 0.864 (+/- 0.002) [Ada Boost]\n",
      "Test Accuracy: 0.8636 \n",
      "Train CV Accuracy: 0.850 (+/- 0.002) [Bagging]\n",
      "Test Accuracy: 0.8593 \n",
      "Train CV Accuracy: 0.864 (+/- 0.003) [Gradient Boosting]\n",
      "Test Accuracy: 0.8650 \n",
      "Train CV Accuracy: 0.868 (+/- 0.004) [XGBoost]\n",
      "Test Accuracy: 0.8729 \n",
      "CPU times: user 1min 9s, sys: 1.81 s, total: 1min 11s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LR = LogisticRegression(solver='lbfgs', max_iter=10000, random_state=555)\n",
    "RF = RandomForestClassifier(n_estimators = 100, random_state=555)\n",
    "SVM = SVC(random_state=0, probability=True)\n",
    "KNC = KNeighborsClassifier()\n",
    "DTC = DecisionTreeClassifier()\n",
    "ABC = AdaBoostClassifier(n_estimators = 100)\n",
    "BC = BaggingClassifier(n_estimators = 100)\n",
    "GBC = GradientBoostingClassifier(n_estimators = 100)\n",
    "# clf_XGB = XGBClassifier(n_estimators = 100, objective= 'binary:logistic', seed=555, use_label_encoder=False)\n",
    "clf_XGB = XGBClassifier(n_estimators = 100, seed=555, use_label_encoder=False, eval_metric='logloss')\n",
    "clfs = []\n",
    "print('5-fold cross validation:\\n')\n",
    "for clf, label in zip([LR, RF, KNC, DTC, ABC, BC, GBC, clf_XGB],\n",
    "                      ['Logistic Regression',\n",
    "                       'Random Forest',\n",
    "                       #'Support Vector Machine',\n",
    "                       'KNeighbors',\n",
    "                       'Decision Tree',\n",
    "                       'Ada Boost',\n",
    "                       'Bagging',\n",
    "                       'Gradient Boosting',\n",
    "                       'XGBoost']):\n",
    "    scores = sklearn.model_selection.cross_val_score(clf, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    print(\"Train CV Accuracy: %0.3f (+/- %0.3f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    md = clf.fit(X_train, y_train)\n",
    "    clfs.append(md)\n",
    "    print(\"Test Accuracy: %0.4f \" % (sklearn.metrics.accuracy_score(clf.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. BUILD A CUSTOM ENSEMBLE (SUPERLEARNER) WITH ANY THREE OF THE MODELS IN TWO LAYERS.  IS IT BETTER?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "from mlens.model_selection import Evaluator\n",
    "from mlens.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = SuperLearner(scorer=accuracy_score, random_state=555, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...a1f9dc0>)],\n",
       "   n_jobs=-1, name='group-2', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x7ff78a1f9dc0>, shuffle=False,\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the first layer\n",
    "ensemble.add([LR, RF, GBC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...a1f9dc0>)],\n",
       "   n_jobs=-1, name='group-3', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x7ff78a1f9dc0>, shuffle=False,\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.add_meta(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 4 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:01\n",
      "Processing layer-4             done | 00:00:00\n",
      "Fit complete                        | 00:00:02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...a1f9dc0>)],\n",
       "   n_jobs=-1, name='group-3', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x7ff78a1f9dc0>, shuffle=False,\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 4 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Processing layer-4             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Accuracy - Train :  0.9092956592956593\n",
      "\n",
      "Predicting 4 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Processing layer-4             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Accuracy - Test :  0.8728501228501229\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy - Train : \", sklearn.metrics.accuracy_score(ensemble.predict(X_train), y_train))\n",
    "print (\"Accuracy - Test : \", sklearn.metrics.accuracy_score(ensemble.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. NOW ADD A PREPROCESSING METHOD OF YOUR CHOICE TO THE DATA BEFORE SEDNING TO YOUR CUSTOM ENSEMBLE FROM #2.  SHOW BOTH RESULTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing method\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "#scaler = StandardScaler()\n",
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to the data\n",
    "X_train_preprocessed = scaler.fit_transform(X_train)\n",
    "X_test_preprocessed = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_preproc = SuperLearner(scorer=accuracy_score, random_state=555, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...1f9dc0>)],\n",
       "   n_jobs=-1, name='group-10', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x7ff78a1f9dc0>, shuffle=False,\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the first layer\n",
    "ensemble_preproc.add([LR, RF, GBC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...1f9dc0>)],\n",
       "   n_jobs=-1, name='group-11', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x7ff78a1f9dc0>, shuffle=False,\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preproc.add_meta(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...1f9dc0>)],\n",
       "   n_jobs=-1, name='group-11', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x7ff78a1f9dc0>, shuffle=False,\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preproc.fit(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Accuracy - Train :  0.8682227682227682\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Accuracy - Test :  0.864987714987715\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy - Train : \", sklearn.metrics.accuracy_score(ensemble_preproc.predict(X_train_preprocessed), y_train))\n",
    "print (\"Accuracy - Test : \", sklearn.metrics.accuracy_score(ensemble_preproc.predict(X_test_preprocessed), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see after using scalar the accuracy is less than the actual accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
